{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae618fe-1a70-48a9-a5f0-f86848b2034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de444b2f-310a-4ed3-a5c3-7d2d361bc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "pio.templates.default = 'plotly_dark'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3f370-b929-4203-8bd4-2134e58c8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import  OrdinalEncoder,OneHotEncoder ,  MinMaxScaler\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e42e0bd-f342-4bfa-ae4b-92ee0c23792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07951e66-f59d-4337-8f5b-a76292951127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_zip(file_path, extract_to='.'):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"The file {file_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        print(f\"Extracted all files to {extract_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28eeea1-6644-4401-8f60-54f18ababc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file = 'playground-series-s4e10.zip'  \n",
    " \n",
    "\n",
    "extract_zip(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce1e8a-fd5c-432f-b8ae-c6ab84c65fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test =  pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df519ac9-d735-4ed2-b21b-65aaa7889971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_column(train_df, test_df, column_name):\n",
    "    if column_name in train_df.columns and column_name in test_df.columns:\n",
    "        train_df = train_df.drop(columns=[column_name])\n",
    "        test_df = test_df.drop(columns=[column_name])\n",
    "        print(f\"Column '{column_name}' has been dropped from both dataframes.\")\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' not found in one or both dataframes.\")\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "column_to_drop = 'id'  \n",
    "\n",
    "train_df, test_df = drop_column(df_train, df_test, column_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db5528-482d-4d4f-960d-5514c29b1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_convert = ['person_home_ownership', 'loan_intent', 'loan_grade','cb_person_default_on_file']  # Replace with your column names\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    train_df[column] = train_df[column].astype('category')\n",
    "    test_df[column] = test_df[column].astype('category')\n",
    "train_df['loan_status'] = train_df['loan_status'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf562ad3-54cd-43df-9c0b-62db52960020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_values_in_train(train_df, test_df, column_name):\n",
    "    if column_name in train_df.columns and column_name in test_df.columns:\n",
    "        train_values = set(train_df[column_name].unique())\n",
    "        test_values = set(test_df[column_name].unique())\n",
    "        \n",
    "        missing_values =    train_values-test_values\n",
    "        \n",
    "        if missing_values:\n",
    "            print(f\"Values in '{column_name}' from train but not in test: {missing_values}\")\n",
    "        else:\n",
    "            print(f\"All unique values in '{column_name}' from train are present in test.\")\n",
    "        \n",
    "        return missing_values\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' not found in one or both dataframes.\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68b1d6-03a6-46ac-a5af-2bc1a5d46819",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check  = train_df.select_dtypes(['category']).columns.tolist()\n",
    "for column in columns_to_check:\n",
    "        print(f\"\\nChecking column: {column}\")\n",
    "        check_unique_values_in_train(train_df, test_df, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03882503-36b7-4e33-b280-b8347ca7d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = 'loan_amnt'  \n",
    "col2 = 'person_income' \n",
    "\n",
    "train_df['loan_percent_income'] = round(train_df[col1] / train_df[col2], 4)*100\n",
    "test_df['loan_percent_income'] = round(test_df[col1] / test_df[col2], 4)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cae8b-44bf-49bb-af63-113422e30565",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = train_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "\n",
    "\n",
    "fig = px.scatter_matrix(\n",
    "    train_df,\n",
    "    dimensions=numerical_cols,\n",
    "    title=\"Pair Plot of Numerical Columns\",\n",
    "    color='loan_status',  \n",
    "    color_discrete_map={True: '#0076a9', False: '#c1ceda'},  \n",
    "    height=1000,width=1000\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174db0de-4c50-4721-a918-f15127487164",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = train_df[numerical_cols].corr().round(3)\n",
    "\n",
    "fig = px.imshow(\n",
    "    correlation_matrix,\n",
    "    color_continuous_scale='Blues',\n",
    "    title='Correlation Matrix Heatmap',\n",
    "    labels=dict(x='Features', y='Features', color='Correlation Coefficient'),text_auto=True\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=800, \n",
    "    height=800,  \n",
    ")\n",
    "fig.update_coloraxes(showscale=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a28fe9-803c-428e-970f-7fc9d7994e4f",
   "metadata": {},
   "source": [
    "Heatmap Observations\n",
    "\n",
    "1. Most of the features exhibited very low correlations, with values close to zero, showing weak or no linear relationship between them.\n",
    "2. Two features, **loan_int_rate** and **loan_percent_income**, showed a negative but very weak correlation with **person_income** and **person_emp_length** respectively, showing an inverse relationship.\n",
    "3. Two features, **person_age** and **cb_person_cred_hist_length**, showed a very strong positive correlation with each other, implying a significant linear relationship.\n",
    "4. Also, **loan_amount** and **loan_percent_income** had a positive relation with each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ea065-6a85-4d7d-866c-0a5606327e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_binary_counts_and_percentages(df, column_name):\n",
    "    colors = [ '#c1ceda','#0076a9']  \n",
    "   \n",
    "    counts = df[column_name].value_counts()\n",
    "    percentages = counts / counts.sum() * 100  \n",
    "\n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Count Plot\", \"Percentage Plot\"))\n",
    "\n",
    "    count_trace = go.Bar(\n",
    "        x=counts.index,\n",
    "        y=counts.values,\n",
    "        marker_color=colors, \n",
    "    )\n",
    "    fig.add_trace(count_trace, row=1, col=1)\n",
    "\n",
    "\n",
    "    percentage_trace = go.Bar(\n",
    "        x=percentages.index,\n",
    "        y=percentages.values,\n",
    "        marker_color=colors,  \n",
    "    )\n",
    "    fig.add_trace(percentage_trace, row=1, col=2)\n",
    "    column_name = column_name.replace('_', ' ')\n",
    "    fig.update_layout(\n",
    "        title_text=f\"Distribution of {column_name}\",\n",
    "        xaxis1_title=column_name,\n",
    "        xaxis2_title=column_name,\n",
    "        yaxis_title=\"Counts\",\n",
    "        yaxis2_title=\"Percentage (%)\",\n",
    "        xaxis=dict(tickvals=[0, 1], ticktext=[\"0\", \"1\"], range=[-0.5, 1.5]),  \n",
    "        xaxis2=dict(tickvals=[0, 1], ticktext=[\"0\", \"1\"], range=[-0.5, 1.5]),  \n",
    "        showlegend=False\n",
    " \n",
    "    )\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_binary_counts_and_percentages(train_df, 'loan_status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc6a15-bedf-443e-9a78-f745db5ccf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions_plotly(train_df, test_df,rows=3, cols=3):\n",
    "    train_color = '#004c6d'\n",
    "    test_color = '#d0d8e0'\n",
    "    numeric_columns = train_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    \n",
    "    valid_columns = [col for col in numeric_columns if col in test_df.columns]\n",
    "    \n",
    "    total_plots = len(valid_columns)\n",
    "    total_rows = math.ceil(total_plots / cols)  \n",
    "    \n",
    "    fig = make_subplots(rows=total_rows, cols=cols, shared_xaxes=False, \n",
    "                        subplot_titles=[f'Distribution of {col.replace('_',' ')}' for col in valid_columns])\n",
    "    \n",
    "    for i, column in enumerate(valid_columns):\n",
    "        row = (i // cols) + 1\n",
    "        col = (i % cols) + 1\n",
    "        \n",
    "     \n",
    "        train_trace = go.Histogram(x=train_df[column], name='Train' if i == 0 else '', \n",
    "                                   marker_color=train_color, opacity=0.8, nbinsx=100, \n",
    "                                   showlegend=(i == 0))\n",
    "        \n",
    "\n",
    "        test_trace = go.Histogram(x=test_df[column], name='Test' if i == 0 else '', \n",
    "                                  marker_color=test_color, opacity=0.9, nbinsx=100, \n",
    "                                  showlegend=(i == 0))\n",
    "        \n",
    "\n",
    "        fig.add_trace(train_trace, row=row, col=col)\n",
    "        fig.add_trace(test_trace, row=row, col=col)\n",
    "        \n",
    "\n",
    "        fig.update_xaxes(title_text=column.replace('_',' '), row=row, col=col)\n",
    "    \n",
    "\n",
    "    fig.update_layout(height=1000, width=1200, title_text=\"Distribution of Train and Test Columns\", \n",
    "                      barmode='overlay', showlegend=True)\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99bd549-8da9-4086-b65b-65042c071fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distributions_plotly(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fdf715-657f-425f-ab7b-d9bb90424662",
   "metadata": {},
   "source": [
    "1. Train and test data show similar distribution across all the numerical columns.\n",
    "2. The following two columns show values above 100 in the training data and need to be removed:\n",
    "   - **person age**\n",
    "   - **person emp length**\n",
    "   - above two columns have same value of 123\n",
    "3. There were few people paying more loan as percentage of income in both train and test data.\n",
    "4. It would be very much sensible to create a catgorical column for cb_person_cred_hist_length as short, medium and long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e4647-6721-4469-9a7b-829f1ccd2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-float('inf'), 4, 10, float('inf')]  \n",
    "labels = ['SHORT', 'MEDIUM', 'LONG']  \n",
    "\n",
    "train_df['cred_hist_length_cat'] = pd.cut(train_df['cb_person_cred_hist_length'], bins=bins, labels=labels)\n",
    "test_df['cred_hist_length_cat'] = pd.cut(test_df['cb_person_cred_hist_length'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce152ad-4ac1-412e-a4e5-88e7fdeb2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['person_age']>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fbade6-07fc-46bc-8ac4-cc57d6ec982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df['person_emp_length']>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b25a46-06b8-4d68-92a6-ddfc6aa53072",
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = 'person_age'  \n",
    "col2 = 'person_emp_length'  \n",
    "threshold = 100  \n",
    "\n",
    "\n",
    "mask = (train_df[col1] > threshold) | (train_df[col2] > threshold)\n",
    "\n",
    "\n",
    "train_df = train_df[~mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad93725-5320-4773-b672-f0a0a2c06e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[train_df.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52db4478-4067-49dc-9989-0d240984638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548b6fc-5418-4858-8096-3774833dbca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_percentage_all(train_df, test_df):\n",
    " \n",
    "    categorical_columns = train_df.select_dtypes(include=['category']).columns.tolist()\n",
    "    \n",
    "    num_cols = 2\n",
    "    num_rows = math.ceil(len(categorical_columns) / num_cols)\n",
    "    \n",
    "    subplot_titles = [col.replace('_', ' ') for col in categorical_columns]\n",
    "\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols, subplot_titles=subplot_titles, shared_yaxes=True)\n",
    "   \n",
    "    for i, column in enumerate(categorical_columns):\n",
    "        row = (i // num_cols) + 1\n",
    "        col = (i % num_cols) + 1\n",
    "        \n",
    "        train_percent = (train_df[column].value_counts(normalize=True) * 100).reset_index()\n",
    "        train_percent.columns = [column, 'Percentage']\n",
    "        \n",
    "        test_percent = (test_df[column].value_counts(normalize=True) * 100).reset_index()\n",
    "        test_percent.columns = [column, 'Percentage']\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(x=train_percent[column], y=train_percent['Percentage'], name='Train', \n",
    "                   marker=dict(color='#004c6d'), showlegend=(i == 0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(x=test_percent[column], y=test_percent['Percentage'], name='Test', \n",
    "                   marker=dict(color='#d0d8e0'), showlegend=(i == 0)),\n",
    "            row=row, col=col\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(height=800, width=1000, title_text=\"Categorical Column Distribution (Train vs Test)\",\n",
    "                      barmode='group',showlegend=True)\n",
    "    fig.write_image(\"3.jpeg\",width=2000, height=500)\n",
    "\n",
    "    \n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf0303e-2f82-427d-87d8-7743f0d9f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 28, 50, 100] \n",
    "labels = ['YOUNG', 'MIDDLE', 'ELDER']  \n",
    "\n",
    "train_df['age_category'] = pd.cut(train_df['person_age'], bins=bins, labels=labels)\n",
    "test_df['age_category'] = pd.cut(test_df['person_age'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06374f38-24c8-4167-9614-7b04560aeb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_percentage_all(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ab7db-3f4a-409c-9e12-57af31296b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(train_df, test_df, target_column, ordinal_columns):\n",
    " \n",
    "\n",
    "    X = train_df.drop(columns=[target_column])\n",
    "    y = train_df[target_column]\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    categorical_cols = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "    categorical_cols = [col for col in categorical_cols if col not in ordinal_columns]\n",
    "    ordinal_categories = [\n",
    "    ['SHORT', 'MEDIUM', 'LONG'] ,      \n",
    "    ['YOUNG', 'MIDDLE', 'ELDER']   ]\n",
    "  \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('numerical data', MinMaxScaler(), numerical_cols),\n",
    "            ('ordinal data', OrdinalEncoder(categories=ordinal_categories), ordinal_columns),\n",
    "            ('categorical data', Pipeline(steps=[\n",
    "            ('rare label encoder', RareLabelEncoder(tol=0.1, n_categories=2)),\n",
    "            ('onehot encoder', OneHotEncoder(drop='first'))\n",
    "        ]), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "  \n",
    "    display(preprocessor)\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "\n",
    "  \n",
    "    one_hot_cols = preprocessor.named_transformers_['categorical data']['onehot encoder'].get_feature_names_out(categorical_cols)\n",
    "    col_names = numerical_cols + ordinal_columns + one_hot_cols.tolist()\n",
    "    X_train_df = pd.DataFrame(X_train_transformed, columns=col_names)\n",
    "\n",
    "\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    X_test_df = pd.DataFrame(X_test_transformed, columns=col_names)\n",
    "\n",
    " \n",
    "    X_final_test_transformed = preprocessor.transform(test_df)\n",
    "    X_final_test_df = pd.DataFrame(X_final_test_transformed, columns=col_names)\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "    return X_train_df, X_test_df, y_train.reset_index(drop=True), y_test.reset_index(drop=True), X_final_test_df , X_train.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd519ef-11b7-4290-81ce-b7e6a47c7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_final_test ,train_index = create_pipeline(train_df, test_df, 'loan_status', ['cred_hist_length_cat','age_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415a1ce-0855-4752-868b-79e5e4eb30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss',random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(silent=True,random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(verbose=-1,random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99587f3d-795f-4c3b-b1d1-347b083a6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_evaluate_models(classifiers, X_train, y_train, X_test, y_test,):\n",
    "\n",
    "    results = []\n",
    "   \n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"Training model: {name}...\")  \n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        y_train_proba = clf.predict_proba(X_train)[:, 1]\n",
    "        y_test_proba = clf.predict_proba(X_test)[:, 1]\n",
    "        train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "        test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        results.append({\n",
    "            \"Classifier\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train AUC\": train_auc,\n",
    "            \"Test AUC\": test_auc,\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results = results_df.sort_values(by=\"Test AUC\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9f23c-6f11-4921-9308-06b64a27f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline =train_and_evaluate_models(classifiers, X_train, y_train, X_test, y_test)\n",
    "results_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70726739-deb9-4244-b4ce-82df8ba7e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_lgbm(X_train, y_train, X_test):\n",
    "\n",
    "    model = LGBMClassifier(random_state=42, verbose=-1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] \n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Training Accuracy: {train_acc:.6f}\")\n",
    "    print(f\"Testing Accuracy: {test_acc:.6f}\")\n",
    "    print(f\"AUC Score: {auc:.6f}\")\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91327816-5193-4967-b1d4-6f6a67d8a4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = train_and_predict_lgbm(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334016f3-7678-4fb0-814c-d5ca3ba6b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X_train, X_test, y_train, y_test,X_final_test, n_components=2):\n",
    "   \n",
    "    pca = PCA(n_components=n_components,random_state=42)\n",
    "    \n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    X_final_test_pca = pca.transform(X_final_test)\n",
    "\n",
    "    \n",
    "    train_df = pd.DataFrame(X_train_pca, columns=[f'PCA1', f'PCA2'])\n",
    "    train_df['target'] = y_train\n",
    "\n",
    "    test_df = pd.DataFrame(X_test_pca, columns=[f'PCA1', f'PCA2'])\n",
    "    test_df['target'] = y_test\n",
    "\n",
    "    final_test_df = pd.DataFrame(X_final_test_pca, columns=[f'PCA1', f'PCA2'])\n",
    "\n",
    "    \n",
    "    \n",
    "    return train_df, test_df , final_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ccd77e-4cd5-43f4-9369-173db7a7a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_pca , test_df_pca , final_test_df_pca = apply_pca(X_train, X_test, y_train, y_test,X_final_test, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db114a1-3f54-449e-953f-42d4328ef55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "\n",
    "def plot_pca(train_df, test_df, final_test_df):\n",
    "    # Rename columns for consistency\n",
    "    train_df.columns = ['PCA1', 'PCA2', 'target']\n",
    "    test_df.columns = ['PCA1', 'PCA2', 'target']\n",
    "    final_test_df.columns = ['PCA1', 'PCA2']\n",
    "    \n",
    "    fig = make_subplots(rows=3, cols=1,\n",
    "                        subplot_titles=(\n",
    "                            'PCA Projection of Training Data',\n",
    "                            'PCA Projection of Test Data',\n",
    "                            'PCA Projection of Final Test Data'\n",
    "                        ))\n",
    "\n",
    "    fig_train = px.scatter(\n",
    "        train_df, \n",
    "        x='PCA1', \n",
    "        y='PCA2', \n",
    "        color='target',\n",
    "        color_discrete_map={0: '#0076a9', 1: '#c1ceda'}\n",
    "    )\n",
    "    \n",
    "    for trace in fig_train.data:\n",
    "        fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    fig_test = px.scatter(\n",
    "        test_df, \n",
    "        x='PCA1', \n",
    "        y='PCA2', \n",
    "        color='target',\n",
    "        color_discrete_map={0: '#0076a9', 1: '#c1ceda'}\n",
    "    )\n",
    "    \n",
    "    for trace in fig_test.data:\n",
    "        fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "    fig_final_test = px.scatter(\n",
    "        final_test_df, \n",
    "        x='PCA1', \n",
    "        y='PCA2'\n",
    "    )\n",
    "    \n",
    "    for trace in fig_final_test.data:\n",
    "        fig.add_trace(trace, row=3, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=900, \n",
    "        width=1000, \n",
    "        title_text='PCA Projection of Datasets',\n",
    "        showlegend=True  \n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title_text='PCA1', matches='x')  \n",
    "    fig.update_yaxes(title_text='PCA2', matches='y')  \n",
    "\n",
    "    for i, trace in enumerate(fig.data):\n",
    "        if i > 1:  \n",
    "            trace.showlegend = False\n",
    "\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58feffbf-4095-4745-a434-a77caa40f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca(train_df_pca , test_df_pca , final_test_df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9706bc-d14b-4e24-8506-d3038c18fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def assign_clusters(main_df, pca_df, pca_column,train_index):\n",
    "\n",
    "    conditions = [\n",
    "        (pca_df[pca_column] <= -0.5),                  \n",
    "        (pca_df[pca_column] >= 0) & (pca_df[pca_column] <= 0.5),  \n",
    "        (pca_df[pca_column] > 0.5) & (pca_df[pca_column] <= 1),   \n",
    "        (pca_df[pca_column] > 1.4) & (pca_df[pca_column] <= 2), \n",
    "        (pca_df[pca_column] > 2),\n",
    "    ]\n",
    "\n",
    "    cluster_labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "    pca_df['cluster'] = np.select(conditions, cluster_labels, default='Outlier')\n",
    " \n",
    "    main_df.loc[train_index,'cluster'] = pca_df['cluster'].values\n",
    "    \n",
    "    return main_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e436f2-7594-48bd-8b19-71e16fe865fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = train_df.copy()\n",
    "clustered_df = assign_clusters(main_df, train_df_pca, 'PCA1',train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c518ce-61e7-4469-8f0f-b52dbcdddd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_by_clusters(clustered_df, feature1, feature2, clusters):\n",
    "   \n",
    "    feature1_colors = {\n",
    "        'SHORT': '#122f5c',  \n",
    "        'MEDIUM': '#c33f75', \n",
    "        'LONG': '#ffa600'   \n",
    "    }\n",
    "\n",
    "    feature2_colors = {\n",
    "        'YOUNG': '#122f5c', \n",
    "        'MIDDLE': '#c33f75',  \n",
    "        'ELDER': '#ffa600'   \n",
    "    }\n",
    "\n",
    "    num_cols = 2\n",
    "    num_rows = len(clusters) \n",
    "    \n",
    "    subplot_titles = [f'Cluster {cluster}' for cluster in clusters for _ in range(2)]\n",
    "    fig = make_subplots(rows=num_rows, cols=num_cols,\n",
    "                        subplot_titles=subplot_titles,\n",
    "                        vertical_spacing=0.1)\n",
    "\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        cluster_data = clustered_df[clustered_df['cluster'] == cluster]\n",
    "\n",
    "        counts_feature1 = cluster_data[feature1].value_counts().sort_index().reset_index()\n",
    "        counts_feature1.columns = [feature1, 'Count']\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=counts_feature1[feature1], \n",
    "                y=counts_feature1['Count'],\n",
    "                name=feature1, \n",
    "                marker=dict(color=[feature1_colors.get(cat, '#000000') for cat in counts_feature1[feature1]])\n",
    "            ),\n",
    "            row=i + 1, col=1  \n",
    "        )\n",
    "\n",
    "        counts_feature2 = cluster_data[feature2].value_counts().sort_index().reset_index()\n",
    "        counts_feature2.columns = [feature2, 'Count']\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=counts_feature2[feature2], \n",
    "                y=counts_feature2['Count'],\n",
    "                name=feature2, \n",
    "                marker=dict(color=[feature2_colors.get(cat, '#000000') for cat in counts_feature2[feature2]])\n",
    "            ),\n",
    "            row=i + 1, col=2 \n",
    "        )\n",
    "    for i in range(num_rows):\n",
    "        if i>4:\n",
    "            fig.update_xaxes(title_text=feature1.replace('_', ' '), row=i + 1, col=1)\n",
    "            fig.update_xaxes(title_text=feature2.replace('_', ' '), row=i + 1, col=2)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Distribution of Important Catgeorical Features Across Clusters',\n",
    "        xaxis_title='',\n",
    "        yaxis_title='Count',\n",
    "        height=800,\n",
    "        width=1000,\n",
    "        showlegend=False\n",
    "\n",
    "        \n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clusters = ['1', '2', '3', '4','5', 'Outlier']\n",
    "plot_by_clusters(clustered_df, 'cred_hist_length_cat', 'age_category', clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53dbe6d-f3fd-48a4-9f5d-a51429349edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def plot_dimensionality_reduction_with_pred(test_df_pca, y_pred):\n",
    "    test_df_pca['y_pred'] = y_pred\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                        subplot_titles=(\n",
    "                            'PCA Projection - True Test Labels',\n",
    "                            'PCA Projection - Predicted Labels'\n",
    "                        ))\n",
    "\n",
    "    fig_true = px.scatter(\n",
    "        test_df_pca, \n",
    "        x='PCA1', \n",
    "        y='PCA2', \n",
    "        color='target',\n",
    "        color_discrete_map={0: '#0076a9', 1: '#c1ceda'}\n",
    "    )\n",
    "    \n",
    "    for trace in fig_true.data:\n",
    "        fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "    fig_pred = px.scatter(\n",
    "        test_df_pca, \n",
    "        x='PCA1', \n",
    "        y='PCA2', \n",
    "        color='y_pred',\n",
    "        color_discrete_map={0: '#0076a9', 1: '#c1ceda'}\n",
    "    )\n",
    "    \n",
    "    for trace in fig_pred.data:\n",
    "        fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=900, \n",
    "        width=1000, \n",
    "        title_text='PCA Projection with True and Predicted Labels',\n",
    "        showlegend=True  \n",
    "    )\n",
    "    \n",
    "\n",
    "    fig.update_xaxes(title_text='PCA1', matches='x')  \n",
    "    fig.update_yaxes(title_text='PCA2', matches='y')  \n",
    "    for i, trace in enumerate(fig.data):\n",
    "        if i > 1:\n",
    "            trace.showlegend = False\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "    return test_df_pca\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca61e07-317f-4896-852b-e0e02f097fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_pca = plot_dimensionality_reduction_with_pred(test_df_pca, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f83bb5-c784-4cc3-9fb4-ab841c7c91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_classification_comparison(test_df):\n",
    "\n",
    "    conditions = [\n",
    "        (test_df['target'] == 1) & (test_df['y_pred'] == 1),  \n",
    "        (test_df['target'] == 0) & (test_df['y_pred'] == 0),  \n",
    "        (test_df['target'] == 0) & (test_df['y_pred'] == 1),  \n",
    "        (test_df['target'] == 1) & (test_df['y_pred'] == 0)   \n",
    "    ]\n",
    "    choices = ['True Positive', 'True Negative', 'False Positive', 'False Negative']\n",
    "    test_df['classification'] = np.select(conditions, choices, default='Unknown')\n",
    "\n",
    "    classification_colors = {\n",
    "        'True Positive': '#0076a9',\n",
    "        'True Negative': '#c1ceda',\n",
    "        'False Positive': '#ff6666',\n",
    "        'False Negative': '#ffcc00'\n",
    "    }\n",
    "\n",
    "    fig_comparison = px.scatter(\n",
    "        test_df,\n",
    "        x=f'PCA1',\n",
    "        y=f'PCA2',\n",
    "        color='classification',\n",
    "        title=f'PCA Projection (True/False Positives/Negatives)',\n",
    "        color_discrete_map=classification_colors,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "    fig_comparison.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398c28a-301a-4597-afeb-8a2151f61174",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_classification_comparison(test_df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba0eae3-483d-485a-9025-6b3ade7a96f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "condition = (test_df_pca['PCA1'] < -0.5) & (\n",
    "    (test_df_pca['classification'] == 'False Negative') | \n",
    "    (test_df_pca['classification'] == 'False Positive')\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b081fb-a24d-43c6-89fe-ddca74e529f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = test_df_pca[condition]\n",
    "\n",
    "sampled_df = filtered_df.sample(frac=0.5, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a733c-00f6-4d4d-abe8-00924d9f9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data_by_indexes(X_train, X_test, y_train, y_test, indexes):\n",
    "    X_to_move = X_test.loc[indexes]\n",
    "    y_to_move = y_test.loc[indexes]\n",
    "    \n",
    "    X_test = X_test.drop(indexes).reset_index(drop=True)\n",
    "    y_test = y_test.drop(indexes).reset_index(drop=True)\n",
    "    \n",
    "    X_train = pd.concat([X_train, X_to_move], ignore_index=True).reset_index(drop=True)\n",
    "    y_train = pd.concat([y_train, y_to_move], ignore_index=True).reset_index(drop=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fa4e51-e70f-4a96-8ca7-b90bec408669",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = move_data_by_indexes(X_train, X_test, y_train, y_test, sampled_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0262a-3505-441e-8067-16ccedb8157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline_2 = train_and_evaluate_models(classifiers, X_train, y_train, X_test, y_test)\n",
    "results_baseline_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754a24a-ab69-4164-bf54-30084032eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = LGBMClassifier(verbose=-1,random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1] \n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc:.6f}\")\n",
    "print(f\"Testing Accuracy: {test_acc:.6f}\")\n",
    "print(f\"AUC Score: {auc:.6f}\")\n",
    "\n",
    "final_test_pred = model.predict_proba(X_final_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca9ffb-bea6-4ed6-9690-6011c5148a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_csv(y_test_auc, output_csv_name,input_csv='sample_submission.csv'):\n",
    "    submission_df = pd.read_csv(input_csv)\n",
    "    \n",
    "    submission_df['loan_status'] = y_test_auc\n",
    "    \n",
    "    submission_df.to_csv(output_csv_name, index=False)\n",
    "    print(f\"Predictions saved to {output_csv_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2daec-c027-4cae-a0d9-d5cfc0f5634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_predictions_to_csv(final_test_pred, 'submission.csv',input_csv='sample_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (Kaggle)",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
